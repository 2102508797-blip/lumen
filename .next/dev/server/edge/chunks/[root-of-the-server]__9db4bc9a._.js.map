{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 16, "column": 0}, "map": {"version":3,"sources":["turbopack:///[project]/app/api/chat/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server'\nimport OpenAI from 'openai'\n\nexport const runtime = 'edge'\n\nconst openai = new OpenAI({\n  apiKey: process.env.EMERGENT_LLM_KEY || '',\n  baseURL: 'https://api.emergent.ai/v1',\n})\n\nexport async function POST(req: NextRequest) {\n  try {\n    // Parse request body\n    const body = await req.json()\n    const { messages, model = 'gpt-4o-mini' } = body\n\n    console.log('Chat API called with:', { \n      messageCount: messages?.length, \n      model,\n      hasKey: !!process.env.EMERGENT_LLM_KEY \n    })\n\n    if (!messages || !Array.isArray(messages)) {\n      console.error('Invalid messages:', messages)\n      return NextResponse.json(\n        { error: 'Messages array is required' },\n        { status: 400 }\n      )\n    }\n\n    // Check API key\n    if (!process.env.EMERGENT_LLM_KEY) {\n      console.error('EMERGENT_LLM_KEY not found in environment')\n      return NextResponse.json(\n        { error: 'API key not configured. Please check server configuration.' },\n        { status: 500 }\n      )\n    }\n\n    console.log('Calling OpenAI API...')\n    \n    const completion = await openai.chat.completions.create({\n      model,\n      messages,\n      temperature: 0.7,\n      max_tokens: 1000,\n    })\n\n    console.log('OpenAI response received:', {\n      hasContent: !!completion.choices[0]?.message?.content,\n      usage: completion.usage\n    })\n\n    const responseMessage = completion.choices[0]?.message?.content\n\n    if (!responseMessage) {\n      console.error('No content in OpenAI response')\n      return NextResponse.json(\n        { error: 'No response generated from AI' },\n        { status: 500 }\n      )\n    }\n\n    return NextResponse.json({\n      message: responseMessage,\n      usage: completion.usage,\n      success: true\n    })\n  } catch (error: any) {\n    console.error('ChatGPT API Error:', error)\n    console.error('Error details:', {\n      message: error.message,\n      stack: error.stack,\n      response: error.response?.data\n    })\n    \n    return NextResponse.json(\n      { \n        error: error.message || 'Failed to get response from ChatGPT',\n        details: error.response?.data?.error?.message || error.toString(),\n        success: false\n      },\n      { status: 500 }\n    )\n  }\n}\n"],"names":[],"mappings":";;;;;;AAAA;AAAA;AACA;AAAA;;;AAEO,MAAM,UAAU;AAEvB,MAAM,SAAS,IAAI,2LAAM,CAAC;IACxB,QAAQ,QAAQ,GAAG,CAAC,gBAAgB,IAAI;IACxC,SAAS;AACX;AAEO,eAAe,KAAK,GAAgB;IACzC,IAAI;QACF,qBAAqB;QACrB,MAAM,OAAO,MAAM,IAAI,IAAI;QAC3B,MAAM,EAAE,QAAQ,EAAE,QAAQ,aAAa,EAAE,GAAG;QAE5C,QAAQ,GAAG,CAAC,yBAAyB;YACnC,cAAc,UAAU;YACxB;YACA,QAAQ,CAAC,CAAC,QAAQ,GAAG,CAAC,gBAAgB;QACxC;QAEA,IAAI,CAAC,YAAY,CAAC,MAAM,OAAO,CAAC,WAAW;YACzC,QAAQ,KAAK,CAAC,qBAAqB;YACnC,OAAO,kMAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA6B,GACtC;gBAAE,QAAQ;YAAI;QAElB;QAEA,gBAAgB;QAChB,IAAI,CAAC,QAAQ,GAAG,CAAC,gBAAgB,EAAE;YACjC,QAAQ,KAAK,CAAC;YACd,OAAO,kMAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA6D,GACtE;gBAAE,QAAQ;YAAI;QAElB;QAEA,QAAQ,GAAG,CAAC;QAEZ,MAAM,aAAa,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACtD;YACA;YACA,aAAa;YACb,YAAY;QACd;QAEA,QAAQ,GAAG,CAAC,6BAA6B;YACvC,YAAY,CAAC,CAAC,WAAW,OAAO,CAAC,EAAE,EAAE,SAAS;YAC9C,OAAO,WAAW,KAAK;QACzB;QAEA,MAAM,kBAAkB,WAAW,OAAO,CAAC,EAAE,EAAE,SAAS;QAExD,IAAI,CAAC,iBAAiB;YACpB,QAAQ,KAAK,CAAC;YACd,OAAO,kMAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAAgC,GACzC;gBAAE,QAAQ;YAAI;QAElB;QAEA,OAAO,kMAAY,CAAC,IAAI,CAAC;YACvB,SAAS;YACT,OAAO,WAAW,KAAK;YACvB,SAAS;QACX;IACF,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,sBAAsB;QACpC,QAAQ,KAAK,CAAC,kBAAkB;YAC9B,SAAS,MAAM,OAAO;YACtB,OAAO,MAAM,KAAK;YAClB,UAAU,MAAM,QAAQ,EAAE;QAC5B;QAEA,OAAO,kMAAY,CAAC,IAAI,CACtB;YACE,OAAO,MAAM,OAAO,IAAI;YACxB,SAAS,MAAM,QAAQ,EAAE,MAAM,OAAO,WAAW,MAAM,QAAQ;YAC/D,SAAS;QACX,GACA;YAAE,QAAQ;QAAI;IAElB;AACF"}}]
}